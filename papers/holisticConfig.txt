One of the reasons that Facebook make so many configuration changes, is that they use configuration so for many different things:

For controlling which users experience a new feature – for example, whether 1%, 5% or 10% of users should see it is managed via configuration
For conducting live experiments (e.g. A/B tests) to try out different parameters
For application-level traffic control

Automation tools periodically make conﬁg changes to shift trafﬁc across regions and perform load tests in production. 
In case of emergency, a conﬁg change kicks off automated cluster/region trafﬁc drain and another conﬁg change disables resource-hungry features of the site. During shadow tests, a conﬁg change starts or stops duplicating live trafﬁc to testing servers. During a ﬁre drill, a conﬁg change triggers fault injection into a production system to evaluate its resilience.

Facebook’s monitoring stack is controlled through conﬁg changes: 1) what monitoring data to collect, 2) monitoring dashboard (e.g., the layout of the key-metric graphs), 3) alert detection rules (i.e., what is considered an anomaly), 4) alert subscription rules (i.e., who should be paged), and 5) automated remediation actions [27], e.g., rebooting or reimaging a server. All these can be dynamically changed without a code upgrade, e.g., as troubleshooting requires collecting more monitoring data.

which is canonically stored in git with a watcher that monitors the git repositories and pushes changes to live systems. 

The config itself is often generated by code, with a defined set of validators for config values also provided in cod

First, the conﬁguration compiler automatically runs validators to verify invariants deﬁned for conﬁgs. Second, a conﬁg change is treated the same as a code change and goes though the same rigorous code review process. Third, a conﬁg change that affects the frontend products automatically goes through continuous integration tests in a sandbox. Lastly, the automated canary testing tool rolls out a conﬁg change to production in a staged fashion.

A conﬁg is associated with a canary spec that describes how to automate testing the conﬁg in production.

For each phase, it speciﬁes the testing target servers, the healthcheck metrics, and the predicates that decide whether the test passes or fails. 

A Git Tailer continuously monitors git for changes and pushes them to Zeus (a forked version of ZooKeeper) for distribution.o

Observers keep a fully replicated read-only copy of the leader’s data. Every server runs a configuration proxy, which randomly picks an observer to connect to. pplications use the proxy to fetch their config

The proxy reads the config from an observer with a watch so that later the observer will notify the proxy if the conﬁg is updated. The proxy stores the conﬁg in an on-disk cache for later reuse. If the proxy fails, the application falls back to read from the on-disk cache directly

The ‘landing strip’ is there to address contention caused by so many engineers making concurrent commits into a shared config repository.

1) receiving diffs from committers, 2) serializing them according to the ﬁrst-come-ﬁrst-served order, and 3) pushing them to the shared git repository on behalf of the committers, without requiring the committers to bring their local repository clones up to date. If there is a true conﬂict between a diff being pushed and some previously committed diffs, the shared git repository rejects the diff, and the error is relayed back to the committer. Only then, the committer has to update her local repository clone and resolve the conﬂict.

While a new product feature is still under development, Facebook engineers commonly release the new code into production early but in a disabled mode, and then use Gatekeeper to incrementally enable it online. If any problem is detected during the rollout, the new code can be disabled instantaneously. 

When a user accesses facebook.com, the Gatekeeper projects are checked in realtime to determine what features to enable for the user. Because the check throughput is high (billions of checks per second) and some Gatekeeper restraints are data intensive, currently Gatekeeper consumes a signiﬁcant percentage of the total CPU of the frontend clusters that consist of hundreds of thousands of servers. 

When an engineer makes a change, it takes about 10 minutes to go through the canary process, 5 seconds to then commit the change into the shared git repository, another 5 seconds for the tailer to fetch the change from the repository and write it to Zeus, and about 4.5 seconds from there to reach hundreds of thousands of servers across multiple continents.

--------------
