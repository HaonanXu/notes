Condition:in a multi-tenant environment, user can

1.define a table and its schema. Note that user can change the schema later on
2. Multiple users can upload to mutlple/same tables at the same time
3. Somehow track the progess of current load and be notified of errors
4. Last one wins for idempotency: e.g. when two uploading same row, one uploading which the other changes schema

-------
Discussion

how do we paritition the import data?
To meet our performance goal: import data can not be processed by a single consumer ,e.g., easily meet the target with 5 parititons, hopeless with 1

Now, multi-tenant case, how will this affect our partition scheme.

Recall Kafka's limitation on over all # of partitions => our partitions shouldnt be fine grained in the end, i.e., if we have topic/partition specific, the # of partitions will scale linearing with our # of clients, this COULD be a potential problem, i.e., 100 tenents => 100 * partitions specific to the tenant
Plus, a single consumer may read from multiple partitions on high level consumer (when you have more partitions than threads, some threads may get data from multiple partitions) so the multi-tenantness must be built in. But building multi-tenantness in for all consumer is hard! => but # of paritions will quickly grow => we will have to add a new cluster

Conclusions:
each import must be processed in parallel
putting all tenants into a single cluster is most likely impractical because A. limit on # of partitions, B.inherently multi-tenantness on all consumer constraint is too hard
-----
Dynamics:

1. schema changes and data upload goes into topic: raw-input 
unvalidated data goes here. Notice whoever writes into this topic must guarantee that the schema change must appear before new rows 

2. consuming raw-input
if it is schema change: update local state to include new schema. the schema change message needs to go into validated-input as well
if it is data change: consult local state to get schema, and validate the row against the schema
	if data change is valid go into the validated-input topic
	otherwise, go into an import-error topic

3. validated-input: almost like raw-input 
this one is ready to go into data sink. Schema information most likely needed

4. consuming validated-input and to data sink
If batching doesnt help, then we need to introduce map reduce jobs
when receive a new message:
if it is schema change, update local state to include new schema
if it is data change. propagate it to data sink

need to introduce batching for performance. Updating process can cause problem as well. see discussion in 5

5. import-error topic
Update the data sink for progress info and detailed error message
Notice that 
1. simple inc is not idempotent, i.e., re-delivery will mess up count
2. probably needs batching to avoid overwhelm data sink with small requests
3. potentially there will be a lot of error messages, so we can not put them into memory. To store large amount of data, use HDFS

