# Job
job.factory.class=org.apache.samza.job.yarn.YarnJobFactory #Use org.apache.samza.job.local.ThreadJobFactory for dev only
job.name=#TODO: your job name

yarn.package.path=#the path of packaged job, most likely a tarball. Note that this path must be accessible from all potential job runners. Thus, often we need to put it in HDFS in a cluster environment

# Task
task.class=#TODO:full class name of your StreamTask class
task.inputs=kafka.topic-listening-to#TODO:kafka.{topic you are listening to}. Topics separated by comma
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.system=kafka
task.checkpoint.replication.factor=3 # you can use 1 for dev

# Metrics
metrics.reporters=snapshot,jmx
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory
metrics.reporter.snapshot.stream=kafka.metrics
metrics.reporter.jmx.class=org.apache.samza.metrics.reporter.JmxReporterFactory

# Serializers
serializers.registry.json.class=org.apache.samza.serializers.JsonSerdeFactory
serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory


# Systems
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
#systems.kafka.samza.msg.serde=json
#systems.kafka.samza.key.serde=string
systems.kafka.consumer.zookeeper.connect=localhost:2181#TODO: kafka zookeeper address 
systems.kafka.consumer.auto.offset.reset=smallest #TODO: smallest for debugging/dev, you probably want to use larget for production
systems.kafka.producer.bootstrap.servers=localhost:9092 #TODO: list of kafka broker addresses, separated by comma

#TODO: the two settings below ignores saved kafka offsets and always start from beginning. Useful for dev. Need to turn them off for production
systems.kafka.streams.import-load.samza.reset.offset=true #TODO: comment this out for prod!
systems.kafka.streams.import-load.samza.offset.default=oldest#TODO: comment this out for prod!
