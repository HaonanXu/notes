# Job
job.factory.class=org.apache.samza.job.yarn.YarnJobFactory #Use org.apache.samza.job.local.ThreadJobFactory for dev only
#TODO: your job name
job.name=

yarn.package.path=#the path of packaged job, most likely a tarball. Note that this path must be accessible from all potential job runners. Thus, often we need to put it in HDFS in a cluster environment

# Task
#TODO:full class name of your StreamTask class
task.class=
#TODO:kafka.{topic you are listening to}. Topics separated by comma
task.inputs=
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.system=kafka
#task.command.class=class that determisn the environment variables for a container
#task.command.opts=JVM options

# Metrics
metrics.reporters=snapshot,jmx
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory
metrics.reporter.snapshot.stream=kafka.metrics
metrics.reporter.jmx.class=org.apache.samza.metrics.reporter.JmxReporterFactory

# Serializers
serializers.registry.json.class=org.apache.samza.serializers.JsonSerdeFactory
serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory


# Systems
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
#systems.kafka.samza.streams.{topic name}.key.serde=if not set, messages are passed unmodified between the input stream consumer, task, and output stream producer 
#systems.kafka.samza.{topic name}.msg.serde=
#TODO: kafka zookeeper address 
systems.kafka.consumer.zookeeper.connect=localhost:2181
#TODO: smallest for debugging/dev, you probably want to use larget for production
systems.kafka.consumer.auto.offset.reset=smallest 
#TODO: list of kafka broker addresses, separated by comma
systems.kafka.producer.bootstrap.servers=localhost:9092 

#TODO: comment this out for prod!
systems.kafka.streams.{topic}.samza.reset.offset=true 
#TODO: comment this out for prod!
systems.kafka.streams.{topic}.samza.offset.default=oldest
