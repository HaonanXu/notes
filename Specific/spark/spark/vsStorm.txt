Storm:
focused on event processing, eals with each event individually. Task-Parrallel
sub-sec latency
At least once delivery, need to track record as they move
written in Closure
Need trident library to simulate spark batch processing behavior
not direclty on HDFS, uses Zookeeper
use Netty as message channel
relies on remote database for durable storage
one thread per task

Spark: Data-parallel
RDD immutable, method for batching incoming updates in user-defined time intervals that get transofmed into their own RDDs
After that parallel operators can perform computations on RDDs
seconds of latency
each batch is proccessed exactly
written in scala
has YARN support with is not available to Storm
Spark streaming failure scenario: write ahead log + fault tolerate requires a data source taht can replay data (e.g., kafka)
Spark uses combination of Netty and Akka
Standalone resource manager handles master node failure with staby-mastes and ZooKepper

Samza:
stream join better, Spark stream's join has can join only within 2 intervals
unlike storm/spark's topology idea, Samza: each job is just a message at-a-time procesor
output of a procesing task alwasy needs to go back to a message broker
always process,s mesags in the order they appear in the partition, no guarantee of ordering across different input streams of partitionsno such guarantee in Storm
so it is better for keyed data processing
each task includes an embedded k-v store on the same machine
single-threaded processes for container