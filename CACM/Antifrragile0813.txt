approaches: prove the correctness of a system => static analysis and testing laggs behind

create test suits to simulate all failure modes in a test environment => insufficient in maintaining resillience in a large-scale distributed system. The compexity fo designing and executing test that properly capture the behavior of the target system is graeter than that of building the system itself => complex issues are note caught in the tesat environment and manifest themselves in unique and infrequent ways. Latent bugs remain undiscovered and accumulating, only to cause largert problems when the right failure mode occurs

or: induce failures in the system to empirically deomstrate resilience and validate intended behavior => system should behave as expeted to handle failulres within original design parameters

Use actual live system

reduce uncertainty by reluarly inducing failure

option: GameDays: scheduled exercises where failure is manully introduced or simulated to mirror real-worth failure 
=> what if more scalable and automated nonevent so that real failure occurs, it will simply blend in without impact => engineer failure to occur in the live environment

chaos monkey: failure of a virtual instance is the most common type of failure

chaos corilla: entire data center is unavailable? simulates network partition and total zone failure

chaos kong: region failure

latency monkey: deteching when instances beomce unhealthy, but are still working, is more difficult. Need to simulate partially healthy instances. Can be useful when testing teh fault tolerance of a new service by simulating the failure of its dependencies

steps:

1. when new monkey in TEST environment, goal to have neiglibgle or zeor impact on the customer
2. no adverse results are observed in the TEST environment, new monkey is enabled int he production environment. Initially, new monkey is opt-in, runs for a few monthis in this mode, opting in new services over tiem
3. after many services have opted in, new monkey graudates to opt-out mode=> all services are potential targets for the new monkey

Monitoring in failure induction and resilience:
during real event, importatn to stabliize the system and elimitate impace asap => automation inducing failure must be stopped during this time => abilty to ovserve and detect service degradation is an important prerequest to building and enabling automation that causes failure
"What is changed" => ability to record changes to the state of the system,e.g., new deployment, config, external service. change must hbe recored for eays retrieval later (Chronos in Netflix)

Every engineer is an operatoer of the service: eliminate network externalities and misaligned incentives => developers should operate their own services
blameless culture
