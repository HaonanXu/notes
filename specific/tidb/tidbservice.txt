Metadata to keep track of
1. tidb-ansible git hash
2. tfstate

-------------
Sequece of actions
use WAL, log an entry before each step

* create a new directory, write the terraform files into that folder
* terraform apply 
* after getting acked, write terraform state and outputs to persist store
* on the master, checkout tidb-ansible at a specfic version
* based on the terraform output, generate the ansible inventory, persist the inventory potentially 
* execute each step, at each step, WAL into persistence layer
* after all is done, log success, probably use an ID + version approach

------------
Syncher testing plan

Questions:
How to ensure that we don't lose data at all?

Setup steps: defnitely need to automate this
1. turn on the mysql binglog replication
2. config tidb up
3. run the syncer 
	a. remember mysql binlog has a maxsize, that means we have a SLA to fill in terms of downtime
	b. 

This means
1. how do we monitor the health of replicateion -> how does canal do it???
2. even if we assume cluster is HA, we probably want to replicate our tidb into a secondary sandbox anyway!

TODO: run more syncer myself

-----------
Setup:
1. for 1TB of data => project volume * 3 / 300GB
 => now I see I need to dynamically config target size


--------
How expensive is the slave?

This means we need to have a base tidb cluster, which does nothing, but accepts from read slave

and a sandbax that we will sync tidb cluster to play with? 

-------


